# Детекция дефектов речи с помощью скороговорок

# Part 1 (Установка)

### Установка

```bash
git clone https://github.com/dkzmn/speech-defect-detector.git
cd speech-defect-detector
poetry install
poetry shell
pre-commit install
pre-commit run -a
```
### Запуск обучения

```bash
python -m speech_defect_detector.commands train
```

Команда автоматически:
- Скачает данные через DVC
- Загрузит конфигурацию из `configs/config.yaml`
- Запустит обучение модели с использованием PyTorch Lightning
- Залогирует метрики в MLflow
- Сохранит лучшую модель в `checkpoints/`

### Изменение гиперпараметров

Гиперпараметры можно изменить через конфигурационные файлы в директории `configs/`:

- `configs/model/model.yaml` - параметры модели
- `configs/data/data.yaml` - параметры данных
- `configs/training/training.yaml` - параметры обучения
- `configs/logging/logging.yaml` - параметры логирования

Также можно переопределить параметры через командную строку:

```bash
python -m speech_defect_detector.commands train training.batch_size=64 training.learning_rate=0.0005
```

### Структура проекта

```
speech-defect-detector/
├── configs/                 # Конфигурационные файлы Hydra
│   ├── config.yaml
│   ├── model/
│   ├── data/
│   ├── training/
│   └── logging/
├── speech_defect_detector/  # Основной пакет
│   ├── data/                # Модули для работы с данными
│   ├── models/              # Определения моделей
│   ├── training/            # Модули для обучения
│   └── commands.py          # Точка входа CLI
├── data/                    # Данные (управляются через DVC)
├── checkpoints/             # Сохраненные модели
├── pyproject.toml           # Зависимости проекта
├── .pre-commit-config.yaml  # Конфигурация pre-commit
└── README.md
```

### Логирование

Все метрики обучения логируются в MLflow:
- Loss (train/val/test)
- Accuracy
- F1 Score
- ROC-AUC

Также логируются гиперпараметры и git commit ID для воспроизводимости экспериментов.

### PS
- Я, как и полагается, к ВКР еще не приступил, поэтому трейн там чисто условный, мини MLP, трейн заканчивается на 10 эпохе, так как на валидации ничего хорошего не происходит. Но на трейне все падает, переобучается, как и должно. Надеюсь этого достаточно.
- Ограничил python 3.13, тк на Macosx была проблема со связкой python3.14 - pyarrow, но все тестировалось на ubuntu / python 3.10 - без проблем.

---

# Part 2 (from HW1)

# Постановка задачи

Необходимо разработать проект, позволяющий по аудиозаписи определить наличие/отсутствие дефектов речи. Проект включает в себя сравнения различных моделей и подходов, выбор лучшего и реализация сервиса в виде ТГ бота. Проект нужен прежде всего родителям и логопедам для оценки прогресса исправления дефектов речи у детей.

## Формат входных и выходных данных

На вход подается 1 аудиозапись, система дает оценку качества речи (в процентах или бинарный класс)

## Метрики

Так как речь идет о бинарной классификации, то будут использоваться метрики: accuracy, roc-auc, f1. Предположить какие будут получены значения достаточно сложно. Работу над ВКР еще не начинал, но по опыту предыдущих работ, хотел бы получить точность 0.75 и выше.

## Валидация и тест

Предполагается разделение датасета на трейн/тест. В силу небольшого объема датасета вилидационную выборку делать нецелесообразно. Разделять нужно с учетом дисбаланса классов. Воспроизводимость будет обеспечиваться фиксацией random\_state.

## Датасеты

Есть готовый датасет (предоставлен дипломным руководителем), состоящий из 1885 скороговорок отмеченных как хорошие и 907 \- плохие. Общий объем 890 МБ. Проблемой может быть дисбаланс классов и небольшое количество. Возможно, после написания готового сервиса, получится его расширить с помощью привлеченных пользователей. Небольшое пополнение датасета возможно с помощью учебных логопедических пособий, работа над этим ведется. Планируется аугментация данных (возможно разрезание или зашумление семплов). Плюс есть двое своих, один как раз картавит, вторая \- нет, думаю, на несколько процентов это увеличит датасет. Датасет пока хранится локально.

# Моделирование

## Бейзлайн

На первом этапе, после предобработки аудиозаписей, планирую применить несколько моделей из классического ML (например SVM, RF) далее лучшую из них оставить и использовать как эталон для сравнения с DL подходами (начну с трансформера).

## Основная модель

Пропишу явно, что, мой опыт работы в ML/DL со звуком ограничивается использованием Whisper. Поэтому сложно предоставить точный план (курс DL по звуку только начался).
Но я вижу предобработку данных в том, чтобы из аудиофайлов получить числовые признаки максимально подробно описывающие файлы (эмбеддинги, если угодно)
И вот как построить эти эмбеддинги, сохраняя в них те характеристики звука, которые отвечают за дефекты, это мне и предстоит узнать.
Далее с этими эмбеддингами  работаем как с обычным датасетом, применяя все знакомые методы ML/DL

# Внедрение

Планируется написать ТГ-бот, который будет принимать голосовые/кружочки/аудио/видеофайлы а в ответ присылать результат (хорошо/плохо с указанием процентов)
Дальше можно придумать веб\-фронт, который будет показывать родителю/логопеду динамику по привязанным пользователям
Кажется, что дополнительных компонент не потребуется, модель не должна получится слишком большой. Для инференса должно хватить мощности одной машины.
